{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTnWZGV65oSDMQhCNAKZCW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JapiKredi/GenAI_Master_Library/blob/main/Google_Gemini_first_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb5qQGpQCbtf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup\n",
        "\n",
        "The Python SDK for the Gemini API, is contained in the google-generativeai package. Install the dependency using pip:"
      ],
      "metadata": {
        "id": "QUa0LIf6tI1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "fEaEI7SQtJYB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages"
      ],
      "metadata": {
        "id": "WakO0BXMtjSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import pathlib\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown"
      ],
      "metadata": {
        "id": "UKSHRXiEtPBL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The to_markdown function transforms a given text into a markdown formatted text#\n",
        "# So, if you input the text 'â€¢ Hello\\nâ€¢ World', the output will be a markdown object representing the text '> * Hello\\n> * World'.\n",
        "\n",
        "def to_markdown(text):\n",
        "  # This line replaces all bullet points (represented by 'â€¢') in the input text with markdown bullet points (' *').\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  # This line indents every line of the input text with '> '.\n",
        "  # The predicate argument is a function that returns True for all lines, meaning all lines will be indented.\n",
        "  # This line converts the indented text into a markdown object.\n",
        "  # This is useful if you're using a library that can render markdown objects, like IPython.\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n"
      ],
      "metadata": {
        "id": "yv_We46KtqxB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "input_text = \"This is a â€¢ sample text with bullet points.\"\n",
        "result = to_markdown(input_text)\n",
        "\n",
        "display(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "sNOyEyhBtrzB",
        "outputId": "8bb291fa-63b0-4cde-a20c-3a0eceef782f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> This is a   * sample text with bullet points."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup your API key\n",
        "\n",
        "Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio."
      ],
      "metadata": {
        "id": "ZSCFxxBdvoXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://makersuite.google.com/app/apikey\n"
      ],
      "metadata": {
        "id": "Enkjs28yvxVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Colab, add the key to the secrets manager under the \"ðŸ”‘\" in the left panel. Give it the name GOOGLE_API_KEY.\n",
        "\n",
        "Once you have the API key, pass it to the SDK. You can do this in two ways:\n",
        "\n",
        "Put the key in the GOOGLE_API_KEY environment variable (the SDK will automatically pick it up from there).\n",
        "Pass the key to genai.configure(api_key=...)"
      ],
      "metadata": {
        "id": "ZPHeAWC5v0bJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "Yiwx6kkRvO4t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Gemini in your environment\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "ufX2piE2wAZu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fetche a list of available generative AI models from the genai library and then prints information about each model.\n",
        "for m in genai.list_models():\n",
        "  print(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tAIk4ItZwxo5",
        "outputId": "aa1e2d7f-1a93-4dac-a007-86bfa5c93df1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(name='models/chat-bison-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='PaLM 2 Chat (Legacy)',\n",
            "      description='A legacy text-only model optimized for chat conversations',\n",
            "      input_token_limit=4096,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
            "      temperature=0.25,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/text-bison-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='PaLM 2 (Legacy)',\n",
            "      description='A legacy model that understands text and generates text as an output',\n",
            "      input_token_limit=8196,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
            "      temperature=0.7,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/embedding-gecko-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Embedding Gecko',\n",
            "      description='Obtain a distributed representation of a text.',\n",
            "      input_token_limit=1024,\n",
            "      output_token_limit=1,\n",
            "      supported_generation_methods=['embedText', 'countTextTokens'],\n",
            "      temperature=None,\n",
            "      top_p=None,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro',\n",
            "      description='The best model for scaling across a wide range of tasks',\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
            "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
            "                   'model that supports tuning.'),\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
            "      temperature=0.9,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Latest',\n",
            "      description=('The best model for scaling across a wide range of tasks. This is the latest '\n",
            "                   'model.'),\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-1.0-pro-vision-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Vision',\n",
            "      description='The best image understanding model to handle a broad range of applications',\n",
            "      input_token_limit=12288,\n",
            "      output_token_limit=4096,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.4,\n",
            "      top_p=1.0,\n",
            "      top_k=32)\n",
            "Model(name='models/gemini-1.5-pro-latest',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Pro',\n",
            "      description='Mid-size multimodal model that supports up to 1 million tokens',\n",
            "      input_token_limit=1048576,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      top_p=0.95,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-pro',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro',\n",
            "      description='The best model for scaling across a wide range of tasks',\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      top_p=1.0,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-pro-vision',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.0 Pro Vision',\n",
            "      description='The best image understanding model to handle a broad range of applications',\n",
            "      input_token_limit=12288,\n",
            "      output_token_limit=4096,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.4,\n",
            "      top_p=1.0,\n",
            "      top_k=32)\n",
            "Model(name='models/embedding-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Embedding 001',\n",
            "      description='Obtain a distributed representation of a text.',\n",
            "      input_token_limit=2048,\n",
            "      output_token_limit=1,\n",
            "      supported_generation_methods=['embedContent'],\n",
            "      temperature=None,\n",
            "      top_p=None,\n",
            "      top_k=None)\n",
            "Model(name='models/text-embedding-004',\n",
            "      base_model_id='',\n",
            "      version='004',\n",
            "      display_name='Text Embedding 004',\n",
            "      description='Obtain a distributed representation of a text.',\n",
            "      input_token_limit=2048,\n",
            "      output_token_limit=1,\n",
            "      supported_generation_methods=['embedContent'],\n",
            "      temperature=None,\n",
            "      top_p=None,\n",
            "      top_k=None)\n",
            "Model(name='models/aqa',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Model that performs Attributed Question Answering.',\n",
            "      description=('Model trained to return answers to questions that are grounded in provided '\n",
            "                   'sources, along with estimating answerable probability.'),\n",
            "      input_token_limit=7168,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateAnswer'],\n",
            "      temperature=0.2,\n",
            "      top_p=1.0,\n",
            "      top_k=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this code retrieves all available models, then filters and prints the names of only those models that have the capability to generate textual content.\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "OmTEMH1cw6nc",
        "outputId": "89286e06-e1cf-41f9-bded-6840561eb6dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remark: The genai package also supports the PaLM family of models, but only the Gemini models support the generic, multimodal capabilities of the generateContent method."
      ],
      "metadata": {
        "id": "UDlOxhG8yno2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate text from text inputs\n"
      ],
      "metadata": {
        "id": "xjSeVUa-ys__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates a connection point for you to interact with the \"gemini-pro\" generative AI model through the genai library.\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "2Wo-pAwCxkXl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Magic command:  tells the environment to measure the execution time of the following code line and display the elapsed time.\n",
        "%%time\n",
        "\n",
        "# using the model object (which represents the \"gemini-pro\" model) and calling its generate_content method.\n",
        "# output from generate_content is assigned to the variable response\n",
        "response = model.generate_content(\"What is the meaning of life?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "8gv3Cs1QziDd",
        "outputId": "c0181ca8-00b3-4139-9182-b663a7fd2752"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 133 ms, sys: 15.6 ms, total: 148 ms\n",
            "Wall time: 8.19 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the information stored in the response variable\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkrLtLuN0auj",
        "outputId": "0dfbd6d9-1a67-4908-b89c-d74953aab577"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "response:\n",
              "GenerateContentResponse(\n",
              "    done=True,\n",
              "    iterator=None,\n",
              "    result=glm.GenerateContentResponse({'candidates': [{'content': {'parts': [{'text': 'The meaning of life is a deep philosophical and existential question that has been pondered by humans for centuries. There is no universally accepted answer, as the meaning of life is believed to vary from person to person and may even change over time.\\n\\nHowever, some common themes emerge when exploring the meaning of life. Many people find meaning in:\\n\\n- **Purpose**: Having a sense of purpose or direction can provide a feeling of fulfillment and meaning. This purpose can be related to work, relationships, personal growth, or any other area of life that gives you a sense of accomplishment.\\n\\n- **Values**: Living in accordance with your values and principles can lead to a more meaningful life. When your actions align with what you believe in, you feel a sense of integrity and authenticity.\\n\\n- **Connection**: Meaningful relationships with others can provide a sense of belonging and purpose. Having people you love and who love you can make life feel more fulfilling.\\n\\n- **Contribution**: Feeling like you are making a positive contribution to the world, whether through your work, relationships, or hobbies, can lead to a sense of purpose and meaning.\\n\\n- **Personal Growth**: Embracing opportunities for personal growth, learning, and challenging yourself can help you feel a sense of accomplishment and fulfillment.\\n\\n- **Experiences**: Life is a journey filled with unique and unforgettable experiences. Embracing new experiences and learning from them can help you discover more about yourself and the world around you.\\n\\n- **Finding Beauty and Joy**: Appreciating the beauty and joy in life, both big and small, can help make life feel more meaningful.\\n\\nUltimately, the meaning of life is subjective and personal. There is no right or wrong answer. The most important thing is to find what brings you a sense of purpose, fulfillment, and joy.'}], 'role': 'model'}, 'finish_reason': 1, 'index': 0, 'safety_ratings': [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}], 'token_count': 0, 'grounding_attributions': []}]}),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Provides a markdown text of the text stored in the response variable\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "GFHVOOAe0c_S",
        "outputId": "3725b4e6-ad6a-466b-e111-5d8143a871ea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> The meaning of life is a deep philosophical and existential question that has been pondered by humans for centuries. There is no universally accepted answer, as the meaning of life is believed to vary from person to person and may even change over time.\n> \n> However, some common themes emerge when exploring the meaning of life. Many people find meaning in:\n> \n> - **Purpose**: Having a sense of purpose or direction can provide a feeling of fulfillment and meaning. This purpose can be related to work, relationships, personal growth, or any other area of life that gives you a sense of accomplishment.\n> \n> - **Values**: Living in accordance with your values and principles can lead to a more meaningful life. When your actions align with what you believe in, you feel a sense of integrity and authenticity.\n> \n> - **Connection**: Meaningful relationships with others can provide a sense of belonging and purpose. Having people you love and who love you can make life feel more fulfilling.\n> \n> - **Contribution**: Feeling like you are making a positive contribution to the world, whether through your work, relationships, or hobbies, can lead to a sense of purpose and meaning.\n> \n> - **Personal Growth**: Embracing opportunities for personal growth, learning, and challenging yourself can help you feel a sense of accomplishment and fulfillment.\n> \n> - **Experiences**: Life is a journey filled with unique and unforgettable experiences. Embracing new experiences and learning from them can help you discover more about yourself and the world around you.\n> \n> - **Finding Beauty and Joy**: Appreciating the beauty and joy in life, both big and small, can help make life feel more meaningful.\n> \n> Ultimately, the meaning of life is subjective and personal. There is no right or wrong answer. The most important thing is to find what brings you a sense of purpose, fulfillment, and joy."
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remark: If the API failed to return a result, use GenerateContentRespose.prompt_feedback to see if it was blocked due to safety concerns regarding the prompt."
      ],
      "metadata": {
        "id": "SYdbSz21066a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.prompt_feedback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ViOYuJH0gs0",
        "outputId": "e93c6057-e8e7-4a56-abff-ce53f5931338"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iurKofKX0-Fv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}